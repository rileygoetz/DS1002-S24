{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rileygoetz/DS1002-S24/blob/main/Assignments/07_More_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More pandas exercises\n",
        "\n",
        "Create a Colab notebook. Complete the tasks as specified in the directions. Run each cell to return the desired output. Save your notebook back to your GitHub repository and submit the GitHub URL for your notebook for review."
      ],
      "metadata": {
        "id": "phbaQTT5gy8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Load the following dataset into Colab and perform the requested operations in code.\n",
        "\n",
        " Source: https://ds1002-resources.s3.amazonaws.com/data/ride_sharing.csv"
      ],
      "metadata": {
        "id": "WlPHuSLARJBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pandas and the data\n",
        "import pandas as pd\n",
        "ride = pd.read_csv('https://ds1002-resources.s3.amazonaws.com/data/ride_sharing.csv')"
      ],
      "metadata": {
        "id": "kdFLCHtOg53p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show how many rows and columns are in this dataset\n",
        "print(ride.shape)\n",
        "\n",
        "num_rows, num_columns = ride.shape\n",
        "print(\"Number of rows:\", num_rows)\n",
        "print(\"Number of columns:\", num_columns)"
      ],
      "metadata": {
        "id": "Lfh8suAyhKQW",
        "outputId": "84b7cef7-b162-4153-b1cf-460f408fe5c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25760, 10)\n",
            "Number of rows: 25760\n",
            "Number of columns: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The first column, \"duration\" is seen as a string.\n",
        "# Using two snippets of code, clean this column up so that\n",
        "# is now an integer (int64)\n",
        "\n",
        "ride['duration'] = ride['duration'].str.extract('(\\d+)').astype(int)\n",
        "ride['duration'] = ride['duration'].astype('int64')"
      ],
      "metadata": {
        "id": "KK5-y9nzhMVq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now display the datatypes in the updated dataframe\n",
        "print(ride.dtypes)"
      ],
      "metadata": {
        "id": "QyGJUshvhz1J",
        "outputId": "fdcab687-55a3-4d5b-aa94-2b0382d1c073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duration            int64\n",
            "station_A_id        int64\n",
            "station_A_name     object\n",
            "station_B_id        int64\n",
            "station_B_name     object\n",
            "bike_id             int64\n",
            "user_type           int64\n",
            "user_birth_year     int64\n",
            "user_gender        object\n",
            "tire_size           int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the min and max values of ride durations (the shortest and longest rides)\n",
        "# Hint: If 'df' is the name of your dataframe, simply specify the column name\n",
        "# and then append the .min() or .max() methods.\n",
        "\n",
        "min_duration = ride['duration'].min()\n",
        "print(\"Shortest ride duration:\", min_duration, \"minutes\")\n",
        "\n",
        "max_duration = ride['duration'].max()\n",
        "print(\"Longest ride duration:\", max_duration, \"minutes\")"
      ],
      "metadata": {
        "id": "UCA1OswWh5b5",
        "outputId": "4e9e7ad4-276a-4965-80b1-da5d0b84f215",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shortest ride duration: 1 minutes\n",
            "Longest ride duration: 1372 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe object and populate it with rides that are 60 minutes or less.\n",
        "# Hint: Use the .query() method for the dataframe that we used in class.\n",
        "\n",
        "short_rides_df = ride.query('duration <= 60')\n",
        "\n",
        "print(short_rides_df.head())"
      ],
      "metadata": {
        "id": "K7mStv5kibbA",
        "outputId": "4cb036ee-def7-4bab-deeb-4f0a776a4ce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   duration  station_A_id                                     station_A_name  \\\n",
            "0        12            81                                 Berry St at 4th St   \n",
            "1        24             3       Powell St BART Station (Market St at 4th St)   \n",
            "2         8            67  San Francisco Caltrain Station 2  (Townsend St...   \n",
            "3         4            16                            Steuart St at Market St   \n",
            "4        11            22                              Howard St at Beale St   \n",
            "\n",
            "   station_B_id                   station_B_name  bike_id  user_type  \\\n",
            "0           323               Broadway at Kearny     5480          2   \n",
            "1           118  Eureka Valley Recreation Center     5193          2   \n",
            "2            23    The Embarcadero at Steuart St     3652          3   \n",
            "3            28     The Embarcadero at Bryant St     1883          1   \n",
            "4           350             8th St at Brannan St     4626          2   \n",
            "\n",
            "   user_birth_year user_gender  tire_size  \n",
            "0             1959        Male         26  \n",
            "1             1965        Male         27  \n",
            "2             1993        Male         29  \n",
            "3             1979        Male         26  \n",
            "4             1994        Male         27  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now show both the min and max values of the duration column for your new dataset.\n",
        "min_duration_short_rides = short_rides_df['duration'].min()\n",
        "print(\"Shortest ride duration in the filtered dataset:\", min_duration_short_rides, \"minutes\")\n",
        "\n",
        "max_duration_short_rides = short_rides_df['duration'].max()\n",
        "print(\"Longest ride duration in the filtered dataset:\", max_duration_short_rides, \"minutes\")"
      ],
      "metadata": {
        "id": "v63UdQjNi-w5",
        "outputId": "7e0a5271-f98f-4bdb-f79a-f37d72614968",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shortest ride duration in the filtered dataset: 1 minutes\n",
            "Longest ride duration in the filtered dataset: 60 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the new dataframe, update it so that is ONLY has records where\n",
        "# the tire_size is 26.\n",
        "\n",
        "short_rides_df = short_rides_df.query('tire_size == 26')\n",
        "\n",
        "print(short_rides_df.head())\n"
      ],
      "metadata": {
        "id": "xTzb_j9rjGk2",
        "outputId": "91bf9a40-e5a7-46a2-c7ec-cfc3608abfe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    duration  station_A_id                                     station_A_name  \\\n",
            "0         12            81                                 Berry St at 4th St   \n",
            "3          4            16                            Steuart St at Market St   \n",
            "6         16            67  San Francisco Caltrain Station 2  (Townsend St...   \n",
            "9          5            30     San Francisco Caltrain (Townsend St at 4th St)   \n",
            "12         7             3       Powell St BART Station (Market St at 4th St)   \n",
            "\n",
            "    station_B_id                station_B_name  bike_id  user_type  \\\n",
            "0            323            Broadway at Kearny     5480          2   \n",
            "3             28  The Embarcadero at Bryant St     1883          1   \n",
            "6            107         17th St at Dolores St     1035          2   \n",
            "9             62   Victoria Manalo Draves Park      333          1   \n",
            "12            27       Beale St at Harrison St     1863          3   \n",
            "\n",
            "    user_birth_year user_gender  tire_size  \n",
            "0              1959        Male         26  \n",
            "3              1979        Male         26  \n",
            "6              1981        Male         26  \n",
            "9              1994        Male         26  \n",
            "12             1998        Male         26  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, produce a count of all records with FEMALE riders\n",
        "# using the 26-inch wheeled rental bikes for their rentals of\n",
        "# one hour or less.\n",
        "\n",
        "female_riders_count = short_rides_df.query('user_gender == \"FEMALE\"').count()\n",
        "\n",
        "print(\"Number of records with FEMALE riders:\", female_riders_count['user_gender'])"
      ],
      "metadata": {
        "id": "0cwbfj66jrG9",
        "outputId": "2f12ee21-b95b-4be0-c5d6-da21601a295c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records with FEMALE riders: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Find the file `more-messy-data.csv` on GitHub and upload it into Google Colab.\n",
        "\n",
        "Create a new Pandas DataFrame from that data and perform the following steps."
      ],
      "metadata": {
        "id": "YIlxzTRQSrl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a snippet of code that will display the number of duplicate rows exist in the DF.\n",
        "data = pd.read_csv('more-messy-data.csv')\n",
        "\n",
        "num_duplicate_rows = data.duplicated().sum()\n",
        "\n",
        "print(\"Number of duplicate rows:\", num_duplicate_rows)"
      ],
      "metadata": {
        "id": "6O1caoy6S82Q",
        "outputId": "03614cb2-41d7-4c12-cf21-e1faa47db424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate rows: 287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, remove all duplicate rows using Python.\n",
        "data1 = data.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "-pDZ2xA-S8vd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the FOUR columns involving sepal and petal length and width, update all NaN\n",
        "# values with the column mean.\n",
        "\n",
        "columns_with_nan = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
        "\n",
        "actual_columns = data1.columns\n",
        "missing_columns = [col for col in columns_with_nan if col not in actual_columns]\n",
        "if missing_columns:\n",
        "    print(\"Warning: The following specified columns do not exist in the DataFrame:\", missing_columns)\n",
        "else:\n",
        "    for column in columns_with_nan:\n",
        "        data1[column] = pd.to_numeric(data1[column], errors='coerce')\n",
        "\n",
        "    for column in columns_with_nan:\n",
        "        data1[column] = data1[column].fillna(data1[column].mean())\n",
        "\n",
        "print(data1.head())"
      ],
      "metadata": {
        "id": "Quf-P7L4S8oh",
        "outputId": "43e11c9d-4856-45de-d734-f770037f5b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  sepal_length  sepal_width  petal_length  petal_width    species\n",
            "0   1           3.5      2.90000           1.4          0.5  virginica\n",
            "1   2           3.6      3.20000           3.0          0.5     setosa\n",
            "2   3           3.8      2.98876           2.2          1.5     setosa\n",
            "3   4           5.8      2.70000           2.6          1.2  virginica\n",
            "4   5           4.9      3.60000           3.0          1.2  virginica\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-544158f0ac47>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data1[column] = pd.to_numeric(data1[column], errors='coerce')\n",
            "<ipython-input-18-544158f0ac47>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data1[column] = data1[column].fillna(data1[column].mean())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find any values in the dataframe that are still missing, and delete them.\n",
        "df_cleaned = data1.dropna()\n",
        "\n",
        "print(\"Shape of DataFrame after removing rows with missing values:\", df_cleaned.shape)"
      ],
      "metadata": {
        "id": "en_ReYsAS8f-",
        "outputId": "34d21c4f-3ae5-450c-8f56-c6b9e8149471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame after removing rows with missing values: (963, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many different species are there?\n",
        "num_species = df_cleaned['species'].nunique()\n",
        "\n",
        "print(\"Number of different species:\", num_species)"
      ],
      "metadata": {
        "id": "uqV9IHwDS75a",
        "outputId": "17202f2c-1aba-459a-fb2f-35d21a4271f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different species: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up the 'species' variable so that there are exactly three different values.\n",
        "species_mapping = {\n",
        "    'Species1': ['species1', 'Species1', 'species-1'],\n",
        "    'Species2': ['species2', 'Species2', 'species-2'],\n",
        "    'Species3': ['species3', 'Species3', 'species-3'],\n",
        "}\n",
        "\n",
        "def standardize_species(row):\n",
        "    for standard, variations in species_mapping.items():\n",
        "        if row in variations:\n",
        "            return standard\n",
        "    return row\n",
        "\n",
        "df_cleaned['species'] = df_cleaned['species'].apply(standardize_species)\n",
        "\n",
        "print(df_cleaned['species'].unique())"
      ],
      "metadata": {
        "id": "G2j8HDgYT52P",
        "outputId": "62a0e603-d379-4b26-a9ee-018062d5e0f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['virginica' 'setosa' 'Versicolor' 'setoso' 'Viginica' 'Virginia'\n",
            " 'Virginica' 'Setosa' 'Setosan' 'versicolor']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-fc86863aea0b>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['species'] = df_cleaned['species'].apply(standardize_species)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Bonus:  Regular expressions\n",
        "\n",
        "Ordinary (non-vanity) Virginia license plates have the form `ABC1234`, meaning they have three upper case letters followed by four digits.  Write a regular expression that matches any string of this form (and doesn't match anything else).  Test your expression with code to make sure it works.\n",
        "\n",
        "To figure out out how to do this, start with the sample code below.  The `re` package has various functions related to regular expressions, including for example `match()`, which takes two arguments, first the regular expression and second the test string, and tests to see whether the *beginning* of the `test` string matches the pattern `exp`.\n",
        "\n",
        "Note that `re.match(exp,test)` does not return a boolean variable, as you might expect (in other words, a match doesn't return `True` and a non-match `False`).  The type of object you get is called `re.Match`, which is a data type special to the `re` package.  (The reason for this is that the object contains more information than just whether there is a match or not.) However, you can turn it into a boolean using `bool()` if you want.\n",
        "\n",
        "Include the following in the notebook you submit:\n",
        "\n",
        " 1. A regular expression in a text chunk\n",
        " 2. One or more code chunks in which you test several strings to verify that your regex is correct.\n",
        " 3. Make sure you display the results of testing various strings.\n",
        "\n",
        " See this [documentation page](https://docs.python.org/3/howto/regex.html#regex-howto) for further help."
      ],
      "metadata": {
        "id": "CsMBqFDmX7Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample code for testing whether a string matches a regex\n",
        "\n",
        "# First import this package for working with regular expressions\n",
        "import re\n",
        "\n",
        "# Here is an example.\n",
        "# Play around with different expressions and test strings to see what happens.\n",
        "exp = 'ab+'\n",
        "test = 'aabbbc'\n",
        "\n",
        "if re.match(exp,test):\n",
        "  print(\"match!\")\n",
        "else:\n",
        "  print(\"no match\")\n",
        "\n",
        "# uncomment this line if you want\n",
        "# print(type(re.match(exp,test)))\n",
        "\n",
        "# uncomment this line if you want\n",
        "# print(bool(re.match(exp,test)))"
      ],
      "metadata": {
        "id": "LKbpBAxJZnXp",
        "outputId": "c7981345-99ca-4eb3-8f16-098ab82ff699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no match\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regex = r'^[A-Z]{3}\\d{4}$'\n",
        "\n",
        "test_strings = [\n",
        "    \"ABC1234\",  # Valid\n",
        "    \"abc1234\",  # Invalid: lowercase letters\n",
        "    \"AB1234\",   # Invalid: not enough letters\n",
        "    \"ABCDE1234\", # Invalid: too many letters\n",
        "    \"ABC12345\", # Invalid: too many digits\n",
        "    \"ABC-1234\", # Invalid: contains a dash\n",
        "    \"1234ABC\",  # Invalid: wrong order\n",
        "    \"ABC 1234\"  # Invalid: contains a space\n",
        "]\n",
        "\n",
        "for test_str in test_strings:\n",
        "    match = re.match(regex, test_str)\n",
        "    result = bool(match)\n",
        "    print(f\"'{test_str}':\", \"Match\" if result else \"No match\")"
      ],
      "metadata": {
        "id": "cuw849_LpLKG",
        "outputId": "f746dd6b-7923-43f2-a6b8-36ccd5a6fd55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'ABC1234': Match\n",
            "'abc1234': No match\n",
            "'AB1234': No match\n",
            "'ABCDE1234': No match\n",
            "'ABC12345': No match\n",
            "'ABC-1234': No match\n",
            "'1234ABC': No match\n",
            "'ABC 1234': No match\n"
          ]
        }
      ]
    }
  ]
}